import requests
from urllib.parse import quote
from typing import Dict, Any, Union

# Para usar fora da CrewAI e validar tÃ³pico
#Busca artigo na WikipÃ©dia em portuguÃªs. Se nÃ£o encontrado ou ambÃ­guo, retorna sugestÃµes.
def buscar_artigo_wikipedia(topic: str) -> Dict[str, Union[str, list, int]]:

    try:
        topic = topic.strip()
        if not topic:
            return {"erro": "Nenhum tÃ³pico vÃ¡lido fornecido"}

        base_url = "https://pt.wikipedia.org/w/api.php"
        params = {
            "action": "query",
            "format": "json",
            "prop": "extracts|info|categories",
            "titles": topic,
            "explaintext": True,
            "utf8": 1,
            "redirects": 1,
            "exintro": True
        }

        response = requests.get(base_url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        pages = data.get("query", {}).get("pages", {})
        if not pages or "-1" in pages:
            # Buscar sugestÃµes
            search_params = {
                "action": "query",
                "format": "json",
                "list": "search",
                "srsearch": topic,
                "utf8": 1
            }

            search_response = requests.get(base_url, params=search_params, timeout=10)
            search_data = search_response.json()
            results = search_data.get("query", {}).get("search", [])

            if results:
                suggestions = [res["title"] for res in results[:5]]
                return {
                    "erro": f"TÃ³pico '{topic}' Ã© ambÃ­guo ou nÃ£o encontrado.",
                    "sugestoes": suggestions
                }
            else:
                return {"erro": "Artigo nÃ£o encontrado e nenhuma sugestÃ£o foi encontrada."}

        page = next(iter(pages.values()))
        result = {
            "titulo": page.get("title", topic),
            "extrato": page.get("extract", "Sem conteÃºdo disponÃ­vel"),
            "url": f"https://pt.wikipedia.org/wiki/{quote(page.get('title', topic).replace(' ', '_'))}",
            "ultima_edicao": page.get("touched", ""),
            "tamanho": page.get("length", 0),
            "aviso": []
        }

        for cat in page.get("categories", []):
            if "esboÃ§o" in cat.get("title", "").lower():
                result["aviso"].append("âš ï¸ Este artigo Ã© um esboÃ§o")

        return result

    except requests.exceptions.RequestException as e:
        return {"erro": f"Erro de conexÃ£o: {str(e)}"}
    except Exception as e:
        return {"erro": f"Erro ao processar o artigo: {str(e)}"}


# ğŸ”§ Tool para CrewAI (usando a funÃ§Ã£o acima)
from crewai.tools import tool

# Ferramenta de pesquisa da Wikipedia
@tool("wikipedia_search")
def wikipedia_search(input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tool para agentes da CrewAI.
    Espera receber input_data['description'] com o tÃ³pico a ser buscado.
    """
    if "input_data" in input_data:
        input_data = input_data["input_data"]

    topic = input_data.get("description", "").strip()
    return buscar_artigo_wikipedia(topic)

